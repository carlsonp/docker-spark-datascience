version: '3.3'
services:
  sparkmaster:
    image: 192.168.1.226:5000/sparkmaster
    build: ./sparkmaster/
    hostname: sparkmaster
    ports:
      - target: 8080
        published: 8090
        mode: host
      - target: 8998
        published: 8998
        mode: host
    environment:
      - TZ= "America/Denver"
      #- SPARK_FILE= ${SPARK_FILE}
      #- SPARK_NLP_FILE= ${SPARK_NLP_FILE}
      #- LIVY_FILE= ${LIVY_FILE}
      - APT_CACHE_PROXY= ${APT_CACHE_PROXY}
    command: /spark/startup.sh
    deploy:
      placement:
        constraints:
          - node.role == manager

  sparkworker:
    image: 192.168.1.226:5000/sparkworker
    build: ./sparkworker/
    deploy:
      # https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#replicated-and-global-services
      mode: global # run one task on each node
    environment:
      - TZ= "America/Denver"
      #- SPARK_FILE= ${SPARK_FILE}
      #- SPARK_NLP_FILE= ${SPARK_NLP_FILE}
      #- LIVY_FILE= ${LIVY_FILE}
      - APT_CACHE_PROXY= ${APT_CACHE_PROXY}
    ports:
      - 8081:8081
    depends_on:
      - sparkmaster
    command: /spark/startup.sh

  jupyterlab:
    image: 192.168.1.226:5000/jupyterlab
    build: ./jupyterlab/
    hostname: jupyterlab
    ports:
      - target: 8888
        published: 8888
        mode: host
      - target: 4040
        published: 4040
        mode: host
    volumes:
      - ./jupyterlab/work/:/work
    command: /startup.sh
    environment:
      - JUPYTER_ENABLE_LAB= "yes"
      - TZ= "America/Denver"
      #- SPARK_FILE= ${SPARK_FILE}
      #- SPARK_NLP_FILE= ${SPARK_NLP_FILE}
      #- LIVY_FILE= ${LIVY_FILE}
      - APT_CACHE_PROXY= ${APT_CACHE_PROXY}
    deploy:
      placement:
        constraints:
          - node.role == manager
