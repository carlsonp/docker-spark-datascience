{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, pickle\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor, RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make matplotlib plot sizes larger\n",
    "plt.rcParams['figure.figsize'] = [30, 20]\n",
    "\n",
    "conf = SparkConf().setAppName('Steam Random Forest Regressor').setMaster('spark://sparkmaster:7077')\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g') # memory per executor\n",
    "SparkContext.setSystemProperty('spark.executor.cores', '6') # cores per executor\n",
    "SparkContext.setSystemProperty('spark.executor.instances', '3') # per worker (computer)\n",
    "\n",
    "# https://spark.apache.org/docs/3.0.0-preview/configuration.html#dynamic-allocation\n",
    "# https://stackoverflow.com/questions/26168254/how-to-set-amount-of-spark-executors\n",
    "# https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/\n",
    "\n",
    "# SparkContext.setSystemProperty(\"spark.shuffle.service.enabled\", \"True\") # required for dynamic allocation below\n",
    "# SparkContext.setSystemProperty(\"spark.dynamicAllocation.enabled\", \"True\")\n",
    "# SparkContext.setSystemProperty(\"spark.executor.cores\", \"4\")\n",
    "# SparkContext.setSystemProperty(\"spark.dynamicAllocation.minExecutors\", \"1\")\n",
    "# SparkContext.setSystemProperty(\"spark.dynamicAllocation.maxExecutors\", \"5\")\n",
    "# SparkContext.setSystemProperty('spark.executor.memory', '2g') # memory per executor\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.executor.memory', '2g'),\n",
       " ('spark.driver.host', 'jupyterlab'),\n",
       " ('spark.executor.instances', '3'),\n",
       " ('spark.app.name', 'Steam Random Forest Regressor'),\n",
       " ('spark.app.id', 'app-20210726204145-0005'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.master', 'spark://sparkmaster:7077'),\n",
       " ('spark.app.startTime', '1627353704369'),\n",
       " ('spark.executor.cores', '6'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.port', '32991'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37513355/converting-pandas-dataframe-into-spark-dataframe-error\n",
    "schema = StructType([ StructField(\"type\", StringType(), True)\\\n",
    "                       ,StructField(\"name\", StringType(), True)\\\n",
    "                       ,StructField(\"required_age\", IntegerType(), True)\\\n",
    "                       ,StructField(\"appid\", IntegerType(), True)\\\n",
    "                       ,StructField(\"release_date\", DateType(), True)\\\n",
    "                       ,StructField(\"initial_price\", DoubleType(), True)\\\n",
    "                       ,StructField(\"metacritic_score\", DoubleType(), True)\\\n",
    "                       ,StructField(\"windows\", BooleanType(), True)\\\n",
    "                       ,StructField(\"mac\", BooleanType(), True)\\\n",
    "                       ,StructField(\"linux\", BooleanType(), True)\\\n",
    "                       ,StructField(\"publisher\", StringType(), True)\\\n",
    "                       ,StructField(\"developer\", StringType(), True)\\\n",
    "                       ,StructField(\"number_dlc\", IntegerType(), True)\\\n",
    "                       ,StructField(\"number_genres\", IntegerType(), True)\\\n",
    "                       ,StructField(\"number_categories\", IntegerType(), True)\\\n",
    "                       ,StructField(\"total_recommendations\", DoubleType(), True)\\\n",
    "                       ,StructField(\"release_day_in_year\", DoubleType(), True)\\\n",
    "                       ,StructField(\"sum_recommendations_up\", DoubleType(), True)\\\n",
    "                       ,StructField(\"sum_recommendations_down\", DoubleType(), True)\\\n",
    "                       ,StructField(\"date\", DateType(), True)\\\n",
    "                       ,StructField(\"days_until_discount\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_-1\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_0\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_1\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_2\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_3\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_4\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_players_5\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_-1\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_0\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_1\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_2\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_3\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_4\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_viewers_5\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_-1\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_0\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_1\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_2\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_3\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_4\", DoubleType(), True)\\\n",
    "                       ,StructField(\"start_twitch_rank_5\", DoubleType(), True)\\\n",
    "                       ,StructField(\"hasLootBoxes\", StringType(), True)\\\n",
    "                       ,StructField(\"isMajorTitle\", StringType(), True)\\\n",
    "                       ,StructField(\"medianScore\", DoubleType(), True)\\\n",
    "                       ,StructField(\"numReviews\", DoubleType(), True)\\\n",
    "                       ,StructField(\"numTopCriticReviews\", DoubleType(), True)\\\n",
    "                       ,StructField(\"percentRecommended\", DoubleType(), True)\\\n",
    "                       ,StructField(\"percentile\", DoubleType(), True)\\\n",
    "                       ,StructField(\"tier\", StringType(), True)\\\n",
    "                       ,StructField(\"topCriticScore\", DoubleType(), True)\\\n",
    "                       ,StructField(\"game_type\", StringType(), True)\\\n",
    "                       ,StructField(\"number_platforms\", DoubleType(), True)\\\n",
    "                       ,StructField(\"number_skus\", DoubleType(), True)\\\n",
    "                       ,StructField(\"type_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"hasLootBoxes_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"isMajorTitle_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"tier_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"game_type_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"windows_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"mac_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"linux_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"developer_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"publisher_num\", IntegerType(), True)\\\n",
    "                       ,StructField(\"cluster_prediction\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = sqlContext.read.load(\"/work/testData\", schema=schema)\n",
    "trainingData = sqlContext.read.load(\"/work/trainingData\", schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, type: string, name: string, required_age: string, appid: string, initial_price: string, metacritic_score: string, publisher: string, developer: string, number_dlc: string, number_genres: string, number_categories: string, total_recommendations: string, release_day_in_year: string, sum_recommendations_up: string, sum_recommendations_down: string, days_until_discount: string, start_players_-1: string, start_players_0: string, start_players_1: string, start_players_2: string, start_players_3: string, start_players_4: string, start_players_5: string, start_twitch_viewers_-1: string, start_twitch_viewers_0: string, start_twitch_viewers_1: string, start_twitch_viewers_2: string, start_twitch_viewers_3: string, start_twitch_viewers_4: string, start_twitch_viewers_5: string, start_twitch_rank_-1: string, start_twitch_rank_0: string, start_twitch_rank_1: string, start_twitch_rank_2: string, start_twitch_rank_3: string, start_twitch_rank_4: string, start_twitch_rank_5: string, hasLootBoxes: string, isMajorTitle: string, medianScore: string, numReviews: string, numTopCriticReviews: string, percentRecommended: string, percentile: string, tier: string, topCriticScore: string, game_type: string, number_platforms: string, number_skus: string, type_num: string, hasLootBoxes_num: string, isMajorTitle_num: string, tier_num: string, game_type_num: string, windows_num: string, mac_num: string, linux_num: string, developer_num: string, publisher_num: string, cluster_prediction: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, type: string, name: string, required_age: string, appid: string, initial_price: string, metacritic_score: string, publisher: string, developer: string, number_dlc: string, number_genres: string, number_categories: string, total_recommendations: string, release_day_in_year: string, sum_recommendations_up: string, sum_recommendations_down: string, days_until_discount: string, start_players_-1: string, start_players_0: string, start_players_1: string, start_players_2: string, start_players_3: string, start_players_4: string, start_players_5: string, start_twitch_viewers_-1: string, start_twitch_viewers_0: string, start_twitch_viewers_1: string, start_twitch_viewers_2: string, start_twitch_viewers_3: string, start_twitch_viewers_4: string, start_twitch_viewers_5: string, start_twitch_rank_-1: string, start_twitch_rank_0: string, start_twitch_rank_1: string, start_twitch_rank_2: string, start_twitch_rank_3: string, start_twitch_rank_4: string, start_twitch_rank_5: string, hasLootBoxes: string, isMajorTitle: string, medianScore: string, numReviews: string, numTopCriticReviews: string, percentRecommended: string, percentile: string, tier: string, topCriticScore: string, game_type: string, number_platforms: string, number_skus: string, type_num: string, hasLootBoxes_num: string, isMajorTitle_num: string, tier_num: string, game_type_num: string, windows_num: string, mac_num: string, linux_num: string, developer_num: string, publisher_num: string, cluster_prediction: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o71.load.\n: java.lang.UnsupportedOperationException: empty collection\n\tat org.apache.spark.rdd.RDD.$anonfun$first$1(RDD.scala:1465)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1463)\n\tat org.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:465)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8758fdc3a04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load models in from the previous step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/work/steam-randomforest-model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#gbt_model = CrossValidatorModel.load(\"/work/steam-gbt-model/\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#linear_model = CrossValidatorModel.load(\"/work/steam-linear-model/\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;34m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a string, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clazz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_from_java\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             raise NotImplementedError(\"This Java ML type cannot be loaded into Python currently: %r\"\n",
      "\u001b[0;32m/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o71.load.\n: java.lang.UnsupportedOperationException: empty collection\n\tat org.apache.spark.rdd.RDD.$anonfun$first$1(RDD.scala:1465)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1463)\n\tat org.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:465)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "# load models in from the previous step\n",
    "rf_model = RandomForestRegressor.load(\"/work/steam-randomforest-model/\")\n",
    "#gbt_model = CrossValidatorModel.load(\"/work/steam-gbt-model/\")\n",
    "#linear_model = CrossValidatorModel.load(\"/work/steam-linear-model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.transform(testData)\n",
    "gbt_predictions = gbt_model.transform(testData)\n",
    "linear_predictions = linear_model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"r2: \" + str(r2))\n",
    "\n",
    "rfPred = rf_model.transform(sqlContext.createDataFrame(df))\n",
    "\n",
    "rfResult = rfPred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfResult.days_until_discount, rfResult.prediction, 'bo')\n",
    "plt.xlabel('Actual days until %d%% off' % (percentage_discount_predict))\n",
    "plt.ylabel('Predicted days')\n",
    "plt.suptitle(\"Random Forest Model Performance (RMSE: %f, MAE: %f, R2: %f)\" % (rmse, mae, r2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = rf_model.bestModel\n",
    "bestModel = bestPipeline.stages[1]\n",
    "\n",
    "importances = bestModel.featureImportances\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters\")\n",
    "print('numTrees - ', bestModel.getNumTrees)\n",
    "print('maxDepth - ', bestModel.getOrDefault('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(gbt_predictions)\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = evaluator.evaluate(gbt_predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "r2 = evaluator.evaluate(gbt_predictions)\n",
    "print(\"r2: \" + str(r2))\n",
    "\n",
    "rfPred = gbt_model.transform(sqlContext.createDataFrame(df))\n",
    "\n",
    "rfResult = rfPred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfResult.days_until_discount, rfResult.prediction, 'bo')\n",
    "plt.xlabel('Actual days until %d%% off' % (percentage_discount_predict))\n",
    "plt.ylabel('Predicted days')\n",
    "plt.suptitle(\"GBT Model Performance (RMSE: %f, MAE: %f, R2: %f)\" % (rmse, mae, r2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = gbt_model.bestModel\n",
    "bestModel = bestPipeline.stages[1]\n",
    "\n",
    "importances = bestModel.featureImportances\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters\")\n",
    "print('numTrees - ', bestModel.getNumTrees)\n",
    "print('maxDepth - ', bestModel.getOrDefault('maxDepth'))\n",
    "print('maxIter - ', bestModel.getOrDefault('maxIter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(linear_predictions)\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = evaluator.evaluate(linear_predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "r2 = evaluator.evaluate(linear_predictions)\n",
    "print(\"r2: \" + str(r2))\n",
    "\n",
    "rfPred = gbt_model.transform(sqlContext.createDataFrame(df))\n",
    "\n",
    "rfResult = rfPred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfResult.days_until_discount, rfResult.prediction, 'bo')\n",
    "plt.xlabel('Actual days until %d%% off' % (percentage_discount_predict))\n",
    "plt.ylabel('Predicted days')\n",
    "plt.suptitle(\"Linear Model Performance (RMSE: %f, MAE: %f, R2: %f)\" % (rmse, mae, r2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = linear_model.bestModel\n",
    "bestModel = bestPipeline.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters\")\n",
    "print('regParam - ', bestModel.getOrDefault('regParam'))\n",
    "print('fitIntercept - ', bestModel.getOrDefault('fitIntercept'))\n",
    "print('elasticNetParam - ', bestModel.getOrDefault('elasticNetParam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
