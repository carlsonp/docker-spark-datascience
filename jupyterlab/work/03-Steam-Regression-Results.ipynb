{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, pickle\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import *\n",
    "from IPython.core.display import display, HTML\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make matplotlib plot sizes larger\n",
    "plt.rcParams['figure.figsize'] = [30, 20]\n",
    "\n",
    "conf = SparkConf().setAppName('Steam Random Forest Regressor').setMaster('spark://sparkmaster:7077')\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g') # memory per executor\n",
    "SparkContext.setSystemProperty('spark.executor.cores', '6') # cores per executor\n",
    "SparkContext.setSystemProperty('spark.executor.instances', '3') # per worker (computer)\n",
    "\n",
    "# https://spark.apache.org/docs/3.0.0-preview/configuration.html#dynamic-allocation\n",
    "# https://stackoverflow.com/questions/26168254/how-to-set-amount-of-spark-executors\n",
    "# https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/\n",
    "\n",
    "# SparkContext.setSystemProperty(\"spark.shuffle.service.enabled\", \"True\") # required for dynamic allocation below\n",
    "# SparkContext.setSystemProperty(\"spark.dynamicAllocation.enabled\", \"True\")\n",
    "# SparkContext.setSystemProperty(\"spark.executor.cores\", \"4\")\n",
    "# SparkContext.setSystemProperty(\"spark.dynamicAllocation.minExecutors\", \"1\")\n",
    "# SparkContext.setSystemProperty(\"spark.dynamicAllocation.maxExecutors\", \"5\")\n",
    "# SparkContext.setSystemProperty('spark.executor.memory', '2g') # memory per executor\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.executor.memory', '2g'),\n",
       " ('spark.driver.host', 'jupyterlab'),\n",
       " ('spark.app.id', 'app-20210419213454-0005'),\n",
       " ('spark.driver.port', '35941'),\n",
       " ('spark.executor.instances', '3'),\n",
       " ('spark.app.name', 'Steam Random Forest Regressor'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.master', 'spark://sparkmaster:7077'),\n",
       " ('spark.executor.cores', '6'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.startTime', '1618889694183'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models back in from previous step\n",
    "predictions = pickle.load(open(\"predictions.p\", \"rb\"))\n",
    "gbt_predictions = pickle.load(open(\"gbt_predictions.p\", \"rb\"))\n",
    "linear_predictions = pickle.load(open(\"linear_predictions.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"r2: \" + str(r2))\n",
    "\n",
    "rfPred = cvModel.transform(sqlContext.createDataFrame(df))\n",
    "\n",
    "rfResult = rfPred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfResult.days_until_discount, rfResult.prediction, 'bo')\n",
    "plt.xlabel('Actual days until %d%% off' % (percentage_discount_predict))\n",
    "plt.ylabel('Predicted days')\n",
    "plt.suptitle(\"Random Forest Model Performance (RMSE: %f, MAE: %f, R2: %f)\" % (rmse, mae, r2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = cvModel.bestModel\n",
    "bestModel = bestPipeline.stages[1]\n",
    "\n",
    "importances = bestModel.featureImportances\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters\")\n",
    "print('numTrees - ', bestModel.getNumTrees)\n",
    "print('maxDepth - ', bestModel.getOrDefault('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(gbt_predictions)\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = evaluator.evaluate(gbt_predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "r2 = evaluator.evaluate(gbt_predictions)\n",
    "print(\"r2: \" + str(r2))\n",
    "\n",
    "rfPred = gbt_model.transform(sqlContext.createDataFrame(df))\n",
    "\n",
    "rfResult = rfPred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfResult.days_until_discount, rfResult.prediction, 'bo')\n",
    "plt.xlabel('Actual days until %d%% off' % (percentage_discount_predict))\n",
    "plt.ylabel('Predicted days')\n",
    "plt.suptitle(\"GBT Model Performance (RMSE: %f, MAE: %f, R2: %f)\" % (rmse, mae, r2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = gbt_model.bestModel\n",
    "bestModel = bestPipeline.stages[1]\n",
    "\n",
    "importances = bestModel.featureImportances\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters\")\n",
    "print('numTrees - ', bestModel.getNumTrees)\n",
    "print('maxDepth - ', bestModel.getOrDefault('maxDepth'))\n",
    "print('maxIter - ', bestModel.getOrDefault('maxIter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(linear_predictions)\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = evaluator.evaluate(linear_predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"days_until_discount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "r2 = evaluator.evaluate(linear_predictions)\n",
    "print(\"r2: \" + str(r2))\n",
    "\n",
    "rfPred = gbt_model.transform(sqlContext.createDataFrame(df))\n",
    "\n",
    "rfResult = rfPred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfResult.days_until_discount, rfResult.prediction, 'bo')\n",
    "plt.xlabel('Actual days until %d%% off' % (percentage_discount_predict))\n",
    "plt.ylabel('Predicted days')\n",
    "plt.suptitle(\"Linear Model Performance (RMSE: %f, MAE: %f, R2: %f)\" % (rmse, mae, r2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = linear_model.bestModel\n",
    "bestModel = bestPipeline.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters\")\n",
    "print('regParam - ', bestModel.getOrDefault('regParam'))\n",
    "print('fitIntercept - ', bestModel.getOrDefault('fitIntercept'))\n",
    "print('elasticNetParam - ', bestModel.getOrDefault('elasticNetParam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
